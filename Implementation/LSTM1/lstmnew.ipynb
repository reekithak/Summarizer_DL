{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":17,"outputs":[{"output_type":"stream","text":"/kaggle/input/glove6b100dtxt/glove.6B.100d.txt\n/kaggle/input/summarizer-data/clean_data.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"**Models based Approach**\n- Automatic text summarization is a common problem in machine learning and natural language processing (NLP). There are two approaches to this problem.\nExtractive Summarization- Extractive text summarization done by picking up the most important sentences from the original text in the way that forms the final summary. We do some kind of extractive text summarization to solve our simple reading comprehension exercises. TextRank is a very popular extractive and unsupervised text summarization technique.\n\n\n- Abstractive Summarization-Abstractive text summarization, on the other hand, is a technique in which the summary is generated by generating novel sentences by either rephrasing or using the new words, instead of simply extracting the important sentences. For example, some questions in the reading comprehension might not be straightforward in such cases we do rephrasing or use new words to answer such questions.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/summarizer-data/clean_data.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Unnamed: 0'],axis=1,inplace=True)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                                                Text  \\\n0  ad sales boost time warner profit    quarterly...   \n1  dollar gains on greenspan speech    the dollar...   \n\n                                             Summary  \n0  timewarner said fourth quarter sales rose 2% t...  \n1  the dollar has hit its highest level against t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad sales boost time warner profit    quarterly...</td>\n      <td>timewarner said fourth quarter sales rose 2% t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dollar gains on greenspan speech    the dollar...</td>\n      <td>the dollar has hit its highest level against t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['word_count'] = df['Text'].apply(lambda x: len(str(x).split()))\n\nfor i in range(0,100,10):\n    var = df['word_count'].values\n    var = np.sort(var,axis=None)\n    print(\"Percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\nprint(\"100 percentile value is \",var[-1])","execution_count":10,"outputs":[{"output_type":"stream","text":"Percentile value is 0\nPercentile value is 10\nPercentile value is 20\nPercentile value is 30\nPercentile value is 40\nPercentile value is 50\nPercentile value is 60\nPercentile value is 70\nPercentile value is 80\nPercentile value is 90\n100 percentile value is  12202\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(90,100):\n    var = df['word_count'].values\n    var = np.sort(var,axis=None)\n    print(\"Percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\nprint(\"100 percentile value is \",var[-1])","execution_count":11,"outputs":[{"output_type":"stream","text":"Percentile value is 90\nPercentile value is 91\nPercentile value is 92\nPercentile value is 93\nPercentile value is 94\nPercentile value is 95\nPercentile value is 96\nPercentile value is 97\nPercentile value is 98\nPercentile value is 99\n100 percentile value is  12202\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['word_count_summ'] = df['Summary'].apply(lambda x: len(str(x).split()))\n\nfor i in range(0,100,10):\n    var = df['word_count_summ'].values\n    var = np.sort(var,axis=None)\n    print(\"Percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\nprint(\"100 percentile value is \",var[-1])","execution_count":12,"outputs":[{"output_type":"stream","text":"Percentile value is 0\nPercentile value is 10\nPercentile value is 20\nPercentile value is 30\nPercentile value is 40\nPercentile value is 50\nPercentile value is 60\nPercentile value is 70\nPercentile value is 80\nPercentile value is 90\n100 percentile value is  2073\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(90,100):\n    var = df['word_count_summ'].values\n    var = np.sort(var,axis=None)\n    print(\"Percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\nprint(\"100 percentile value is \",var[-1])","execution_count":13,"outputs":[{"output_type":"stream","text":"Percentile value is 90\nPercentile value is 91\nPercentile value is 92\nPercentile value is 93\nPercentile value is 94\nPercentile value is 95\nPercentile value is 96\nPercentile value is 97\nPercentile value is 98\nPercentile value is 99\n100 percentile value is  2073\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"                                                Text  \\\n0  ad sales boost time warner profit    quarterly...   \n1  dollar gains on greenspan speech    the dollar...   \n2  yukos unit buyer faces loan claim    the owner...   \n\n                                             Summary  word_count  \\\n0  timewarner said fourth quarter sales rose 2% t...         421   \n1  the dollar has hit its highest level against t...         384   \n2  yukos' owner menatep group says it will ask ro...         264   \n\n   word_count_summ  \n0              134  \n1              158  \n2              121  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Summary</th>\n      <th>word_count</th>\n      <th>word_count_summ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad sales boost time warner profit    quarterly...</td>\n      <td>timewarner said fourth quarter sales rose 2% t...</td>\n      <td>421</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dollar gains on greenspan speech    the dollar...</td>\n      <td>the dollar has hit its highest level against t...</td>\n      <td>384</td>\n      <td>158</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>yukos unit buyer faces loan claim    the owner...</td>\n      <td>yukos' owner menatep group says it will ask ro...</td>\n      <td>264</td>\n      <td>121</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_tr , X_tst , y_tr , y_tst = train_test_split(df['Text'],df['Summary'],test_size=0.3,random_state=23,shuffle=True)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"29116    in one of the fastest trials, a man accused of...\n58993    american civil rights activist martin luther k...\n41433    a uk court has directed the seizure of a $492 ...\n32066    a us eatery has banned a customer who left a \"...\n27870    chinese authorities have detained an 18-year-o...\n                               ...                        \n71711    bjp minister anil vij on friday called taj mah...\n9704     the mumbai fire brigade  (mfb) investigation r...\n76726    the maharashtra government will be opening thr...\n92105    two senior immigration officers posted at the ...\n9256     taking a jibe at pm narendra modi, west bengal...\nName: Text, Length: 73598, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading our Glove Model \nembeddings_index = dict()\nf = open('glove.6B.100d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Percentage of words from train text present in Word2vec model\nwords_source_train = []\nfor i in X_tr :\n    #print(i)\n    words_source_train.extend(str(i).split(' '))\n    \n    \n## Find the total number of words in the Train data of Essays.\nprint(\"all the words in the corpus\", len(words_source_train))\n\n\n## Find the unique words in this set of words\nwords_source_train = set(words_source_train)\nprint(\"the unique words in the corpus\", len(words_source_train))\n\n\n## Find the words present in both Glove Vectors as well as our corpus.\ninter_words = set(embeddings_index.keys()).intersection(words_source_train)\nprint(\"The number of words that are present in both glove vectors and our corpus are {} which \\\nis nearly {}% \".format(len(inter_words), np.round((float(len(inter_words))/len(words_source_train))\n*100)))\nwords_corpus_source_train = {}\nwords_glove = set(embeddings_index.keys())\nfor i in words_source_train:\n    if i in words_glove:\n    \n        words_corpus_source_train[i] = embeddings_index[i]\nprint(\"word 2 vec length\", len(words_corpus_source_train))","execution_count":25,"outputs":[{"output_type":"stream","text":"all the words in the corpus 5744142\nthe unique words in the corpus 250570\nThe number of words that are present in both glove vectors and our corpus are 65507 which is nearly 26.0% \nword 2 vec length 65507\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nx_tokenizer = Tokenizer(num_words=1000)\nword_index = x_tokenizer.word_index\nembedding_matrix = np.zeros((len(word_index) + 1, 100))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector","execution_count":27,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Tokenizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-723a69c61afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}